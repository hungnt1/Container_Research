## Cài đặt Kubernetest Cluster trên Centos 7

- Cơ bản tìm hiểu theo topo này
![https://i.imgur.com/NBvX4rh.png]

- A Kubernetes cluster consists of two types of resources:
    - The Master coordinates the cluster
    - Nodes are the workers that run applications

-  Kubernetes Cluster bao gồm 2 thành phần là Master và Worker
    - Master đảm nhiệm quản lý cả cụm, nắm giữ tất cả trạng thái và lập lịch để đặt các ứng dụng lên các worker, đảm nhiệm scale và rolling update các ứng dụng đang chạy
    - Worker hay node có thể là máy chủ vật lý hoặc máy ảo, đảm nhiệm là worker machine trong Kubernetes Cluster. Mỗi node đều có một agent là kubelet để kết nối mới máy chủ Master và quản lý node. Mỗi node sẽ có một tool để quản lý các container ở dưới node có thể là Docker hoặc rkt. Một cluster chạy trên production được khuyến nghị có ít nhất 3 worker.
- Khi thực hiện deploy một ứng dụng  lên Kubernetes, việc cần làm chỉ đơn giản mà gọi máy chủ master và gửi yêu cầu. Máy chủ master sẽ thực hiện điều hướng, lập lịch để các container được khởi động trên các Node. Các node sẽ liên hệ với máy chủ master thông qua API.


### 1. Thực hiện setup hostname, FirewallD và SeLinux

- Cấu hình Hostname

```
hostnamectl set-hostname master
hostnamectl set-hostname worker1
hostnamectl set-hostname worker2
hostnamectl set-hostname worker3
```

- Cấu hình hostname trên các node

```
cat <<EOF> /etc/hosts
127.0.0.1 maste1 127.0.0.1 
127.0.0.1 worker1 127.0.0.1
10.10.203.33 master1
10.10.203.41 worker1
10.10.203.41 worker2
EOF
```

- Thực hiện disable SeLinux

```
setenforce 0
sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux
```

- Cấu hình IPtable

```bash
modprobe br_netfilter

cat <<EOF > /etc/sysctl.d/k8s.conf
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sysctl --system
```

### 2. Cài đặt trên Control Plane Node

- Cài đặt môi trường Runtime ( Docker )

```bash
# Install Docker CE
## Set up the repository
### Install required packages.
yum install -y yum-utils device-mapper-persistent-data lvm2

### Add Docker repository.
yum-config-manager --add-repo \
  https://download.docker.com/linux/centos/docker-ce.repo

## Install Docker CE.
yum update -y && yum install -y \
  containerd.io-1.2.13 \
  docker-ce-19.03.8 \
  docker-ce-cli-19.03.8

## Create /etc/docker directory.
mkdir /etc/docker

# Setup daemon.
cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ]
}
EOF

mkdir -p /etc/systemd/system/docker.service.d

# Restart Docker
systemctl daemon-reload
systemctl restart docker
systemctl start docker kubelet
systemctl enable docker kubelet

```

- Kiểm tra cgroup

```
docker info | grep -i cgroup
 Cgroup Driver: systemd

```

- Cấu hình FirewallD

```
firewall-cmd --permanent --add-port=6443/tcp
firewall-cmd --permanent --add-port=2379-2380/tcp
firewall-cmd --permanent --add-port=10250/tcp
firewall-cmd --permanent --add-port=10251/tcp
firewall-cmd --permanent --add-port=10252/tcp
firewall-cmd –reload
```

- Cấu hình Kubernest Repository

```bash
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF

```

- Cài đặt kubeadm kubectl

```bash
yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes

systemctl enable --now kubelet
```

- Thực hiện init cluster. Sau đó lưu đoạn mã để register, sẽ sử dụng để register dưới các node

```bash
kubeadm init --apiserver-advertise-address=10.10.203.33 --pod-network-cidr=10.20.0.0/16 -v=9
```

Trong đó : - apiserver-advertise-address là đường managment - pod-network-cid: là mạng để các Pods liên hệ với nhau dạng internal ( không nên trùng mạng nào với host và hạ tầng vật lý ở ngoài )

```
W0405 00:29:01.811250   18622 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]
[init] Using Kubernetes version: v1.18.0
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Starting the kubelet
[certs] Using certificateDir folder "/etc/kubernetes/pki"
[certs] Generating "ca" certificate and key
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [master1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.10.203.33]
[certs] Generating "apiserver-kubelet-client" certificate and key
[certs] Generating "front-proxy-ca" certificate and key
[certs] Generating "front-proxy-client" certificate and key
[certs] Generating "etcd/ca" certificate and key
[certs] Generating "etcd/server" certificate and key
[certs] etcd/server serving cert is signed for DNS names [master1 localhost] and IPs [10.10.203.33 127.0.0.1 ::1]
[certs] Generating "etcd/peer" certificate and key
[certs] etcd/peer serving cert is signed for DNS names [master1 localhost] and IPs [10.10.203.33 127.0.0.1 ::1]
[certs] Generating "etcd/healthcheck-client" certificate and key
[certs] Generating "apiserver-etcd-client" certificate and key
[certs] Generating "sa" key and public key
[kubeconfig] Using kubeconfig folder "/etc/kubernetes"
[kubeconfig] Writing "admin.conf" kubeconfig file
[kubeconfig] Writing "kubelet.conf" kubeconfig file
[kubeconfig] Writing "controller-manager.conf" kubeconfig file
[kubeconfig] Writing "scheduler.conf" kubeconfig file
[control-plane] Using manifest folder "/etc/kubernetes/manifests"
[control-plane] Creating static Pod manifest for "kube-apiserver"
[control-plane] Creating static Pod manifest for "kube-controller-manager"
W0405 00:29:19.044012   18622 manifests.go:225] the default kube-apiserver authorization-mode is "Node,RBAC"; using "Node,RBAC"
[control-plane] Creating static Pod manifest for "kube-scheduler"
W0405 00:29:19.044934   18622 manifests.go:225] the default kube-apiserver authorization-mode is "Node,RBAC"; using "Node,RBAC"
[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
 [kubelet-check] Initial timeout of 40s passed.
[apiclient] All control plane components are healthy after 57.032624 seconds
[upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
[kubelet] Creating a ConfigMap "kubelet-config-1.18" in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Skipping phase. Please see --upload-certs
[mark-control-plane] Marking the node master1 as control-plane by adding the label "node-role.kubernetes.io/master=''"
[mark-control-plane] Marking the node master1 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[bootstrap-token] Using token: fda9nx.fmzacmqdvn3hmhj1
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
[kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 10.10.203.33:6443 --token fda9nx.fmzacmqdvn3hmhj1 \
    --discovery-token-ca-cert-hash sha256:750ae2309df90b3abaa526794d625fc2b6288005ff455edeb1a8c9f78607807d

```


### 3. Trên các Worker node

- Cài đặt môi trường Runtime ( Docker )

```bash
# Install Docker CE
## Set up the repository
### Install required packages.
yum install -y yum-utils device-mapper-persistent-data lvm2

### Add Docker repository.
yum-config-manager --add-repo \
  https://download.docker.com/linux/centos/docker-ce.repo

## Install Docker CE.
yum update -y && yum install -y \
  containerd.io-1.2.13 \
  docker-ce-19.03.8 \
  docker-ce-cli-19.03.8

## Create /etc/docker directory.
mkdir /etc/docker

# Setup daemon.
cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ]
}
EOF

mkdir -p /etc/systemd/system/docker.service.d

# Restart Docker
# Restart docker.
systemctl daemon-reload
systemctl restart docker

```

- Kiểm tra cgroup

```
docker info | grep -i cgroup
 Cgroup Driver: systemd

```

- Cấu hình FirewallD

```
firewall-cmd --permanent --add-port=10250/tcp
firewall-cmd --permanent --add-port=30000-32767/tcp
firewall-cmd --reload
```

- Cấu hình Kubernetes Repository

```bash
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF

```

- Cài đặt kubeadm kubectl

```bash
yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes

systemctl enable --now kubelet
```

- Thực hiện join cluster

```
kubeadm join 10.10.203.33:6443 --token fda9nx.fmzacmqdvn3hmhj1 \
    --discovery-token-ca-cert-hash sha256:750ae2309df90b3abaa526794d625fc2b6288005ff455edeb1a8c9f78607807d

```
```
[root@worker1 ~]# kubeadm join 10.10.203.33:6443 --token fda9nx.fmzacmqdvn3hmhj1 \

>     --discovery-token-ca-cert-hash sha256:750ae2309df90b3abaa526794d625fc2b6288005ff455edeb1a8c9f78607807d
>
> W0405 00:45:16.555826 5508 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not set.
> [preflight] Running pre-flight checks

        [WARNING Service-Docker]: docker service is not enabled, please run 'systemctl enable docker.service'

[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml'
[kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.18" ConfigMap in the kube-system namespace
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Starting the kubelet
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:

- Certificate signing request was sent to apiserver and a response was received.
- The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the control-plane to see this node join the cluster.

```

### 4. Network Pods

- Ở trên sử dụng option để sủ dụng Network cho các Pods, tuy nhiên để sử dụng được network cần một interface driver để quản lý các endpoint trong K8S được gọi là **[Container Network Interface](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#cni) (CNI)**
- Danh sách các networking add-on tại đây : [https://kubernetes.io/docs/concepts/cluster-administration/addons/#networking-and-network-policy](https://kubernetes.io/docs/concepts/cluster-administration/addons/#networking-and-network-policy)
- Trong trường hợp này, sẽ sử dụng Calio ( do người dùng đánh giá ) để làm network add-on cho hệ thống

```shell
kubectl apply -f https://docs.projectcalico.org/v3.11/manifests/calico.yaml
````

- Tuy nhiên để thực hiện command, cần phải thực hiện export credential

```bash
export KUBECONFIG=/etc/kubernetes/admin.conf
```

### 5. Cài đặt Ingress Controller

- Cài đặt môi trường Runtime ( Docker )

```bash
# Install Docker CE
## Set up the repository
### Install required packages.
yum install -y yum-utils device-mapper-persistent-data lvm2

### Add Docker repository.
yum-config-manager --add-repo \
  https://download.docker.com/linux/centos/docker-ce.repo

## Install Docker CE.
yum update -y && yum install -y \
  containerd.io-1.2.13 \
  docker-ce-19.03.8 \
  docker-ce-cli-19.03.8

## Create /etc/docker directory.
mkdir /etc/docker

# Setup daemon.
cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ]
}
EOF

mkdir -p /etc/systemd/system/docker.service.d

# Restart Docker
# Restart docker.
systemctl daemon-reload
systemctl restart docker

```

- Kiểm tra cgroup

```
docker info | grep -i cgroup
 Cgroup Driver: systemd

```

- Cấu hình FirewallD

```
firewall-cmd --permanent --add-port=10250/tcp
firewall-cmd --permanent --add-port=30000-32767/tcp
firewall-cmd --reload
```

- Cấu hình Kubernetes Repository

```bash
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF

```

- Cài đặt kubeadm kubectl

```bash
yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes

systemctl enable --now kubelet
```

- Thực hiện join cluster

```
kubeadm join 10.10.203.33:6443 --token fda9nx.fmzacmqdvn3hmhj1 \
    --discovery-token-ca-cert-hash sha256:750ae2309df90b3abaa526794d625fc2b6288005ff455edeb1a8c9f78607807d

```



### 6. Kiểm tra cluster trên máy chủ master

- Kiểm tra thông tin cluster
```
[] kubectl cluster-info

Kubernetes master is running at https://10.10.204.58:6443
KubeDNS is running at https://10.10.204.58:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
```


- Kiểm tra thông tin các node
```
[]  kubectl get nodes
NAME                STATUS   ROLES    AGE   VERSION
worker1.novalocal   Ready    master   8d    v1.18.5
worker2.novalocal   Ready    <none>   8d    v1.18.5
worker3.novalocal   Ready    <none>   8d    v1.18.5

```

## Arch

- Kiến trúc cơ bản
![](https://d33wubrfki0l68.cloudfront.net/7016517375d10c702489167e704dcb99e570df85/7bb53/images/docs/components-of-kubernetes.png)

- Cấu hình không scheduler vào node này
```
kubectl cordon $NODENAME

```

- Lấy danh sách node
```
kubectl get nodes
```


- Kiểm tra trạng thái của node
```
kubectl describe node worker2.novalocal

```
  <!-- 
  - Cơ bản trên Master sẽ bao gồm các thành phần sau ( không dịch sang Tiếng Việt để sát nghĩa nhất):
    - kube-apiserver: The API server is a component of the Kubernetes control plane that exposes the Kubernetes API. The API server is the front end for the Kubernetes control plane.
    - etcd: Consistent and highly-available key value store used as Kubernetes' backing store for all cluster data.
    - kube-scheduler: Control plane component that watches for newly created Pods with no assigned node, and selects a node for them to run on.
    - kube-controller-manager: Control Plane component that runs controller processes.

  - Các thành phần trên node ( worker ) bao gồm:
    - kubelet: An agent that runs on each node in the cluster. It makes sure that containers are running in a Pod.
    - kube-proxy: kube-proxy is a network proxy that runs on each node in your cluster, implementing part of the Kubernetes Service concept.
    - Container runtime: The container runtime is the software that is responsible for running containers.

  - Ngoài ra có 1 số addon
    - DNS: While the other addons are not strictly required, all Kubernetes clusters should have cluster DNS, as many examples rely on it.
    - Web UI (Dashboard): Dashboard is a general purpose, web-based UI for Kubernetes clusters.
    - Container Resource Monitoring Container Resource Monitoring records generic time-series metrics about containers in a central database
    - Cluster-level Logging: A cluster-level logging mechanism is responsible for saving container logs to a central log store with search/browsing interface.
  -->



- Diagram dưới đây hiển thị cách thành phần trong kiến trúc của Kubernetes và cách chúng liên hệ với nhau qua các protocol

![](https://jimmysong.io/kubernetes-handbook/images/kubernetes-high-level-component-archtecture.jpg)


- Kiến trúc cụ thể của Master
![](https://jimmysong.io/kubernetes-handbook/images/kubernetes-master-arch.png)


- Kiếm trúc cụ thể của các Pod Node
![](https://jimmysong.io/kubernetes-handbook/images/kubernetes-node-arch.png)

Các thành phần chính có trong core của Kubeneters:
- etcd được sử dụng để lưu trạng thái của toàn cluster
- apiserver được sử dụng để toàn các tác vụ với các objet, chung cấp thêm các cơ chế xác thực, access cotnrol, API registration
- controller manager đảm nhiệm giữ  trạng thái của các object trong hệ thống , xác định lỗi, tự động mở rộng và rollback
- scheduler đảm nhiệm lập kế hoạch cho các tài nguyên, lập kế hoạch cho Pod và các object khác 
- kubelet đảm nhiệm duy trì vòng đời của container, đảm nhiệm quản lý các Voluem và Network
- Container runtime đảm nhiệm quản lý các image và tác vụ thực hiện trực tiếp với các pods và contaienr trong các Pods
- kube-proxy đảm nhiệm kết nối giữa các service và load balancing cho các Service

Ngoài ra, còn một số thành phần bổ sung cho Kubernetes trong quá trình hoạt động
- CoreDNS đảm nhiệm DNS service
- Ingress Controller cung cấp quản lý external cho Service
- resource monitor cung cấp các output cho các bộ monitor
- Dashboard cung cấp khả năng quản lý cluster thông qua Web UI



- Kiến trúc dạng layer trong Kubernetes
Kiến trúc dạng layer của Kubernetes

![](https://jimmysong.io/kubernetes-handbook/images/kubernetes-layers-arch.png)

- Core layer: core function của Kube, cung cấp các điểm API cho các thao tác bên ngoài
- Application layer: deploy các ứng dụng và điện tuyến cho các ứng dụng
- Management layer: system metric và RBAC
- Interface layer: kubectl command line
- Ecosystem: được sử dụng để lập trình và quản lý cluster thông qua interface layer

## Làm việc với Object trong K8S
- K8S Object là một entry trong cluster. Object môi tả trạng thái của cluster. Chủ yếu các object được sử dụng để
  - What containerized applications are running (and on which nodes)
  - The resources available to those applications 
  - The policies around how those applications behave, such as restart policies, upgrades, and fault-tolerance

- Chủ yếu các Object sẽ gồm 2 phần: spec và status. Spec mô trả trạng thái ổn định của object cần có. Status được Control Plane cập nhật realtime về trạng thái của Object.


- Ví dụ về một object
```
apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 2 # tells deployment to run 2 pods matching the template
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```

- Object trong K8S được sử dụng là yaml, các trường CLI sẽ tự động convert sang JSON để cho API hiểu. Các trường tối thiểu để định nghĩa một Object
  - apiVersion - Which version of the Kubernetes API you're using to create this object
  - kind - What kind of object you want to create
  - metadata - Data that helps uniquely identify the object, including a name string, UID, and optional namespace
  - spec - What state you desire for the object

- Có 2 cách cơ bản để làm việc với object bao gồm thông qua pramater trên command hoặc file cấu hình

- Mỗi object trong cluster sẽ yêu cầu một trường Name và ID. Name sẽ được phố biến trong resource và namespace. UID này sẽ được phổ biến trên toàn cluster. 

- Ví dụ trong namespace default sẽ chỉ có một Pod tên là abcd, tuy nhiên giữa các namespace có thể có nhiều Pod tên là abcd.

- Name cho các Object được sử dụng trong API query theo dạng path có ví dụ  như sau /api/v1/pods/some-name

- UID đươc k8s generate ra nhằm mục đích tránh nhầm lẫn, ví các object có thể trùng tâm giữa các namespace và các resource khác nhau

### Namespace:
- Namespace là một logic không gian riêng cho các resource. Cung cấp một scope limit cho các name của các  resource.
- Xem danh sách namespace
```
kubectl get namespace

``` 

- Khởi tạo resource trong 1 namespace
```
kubectl run nginx --image=nginx --namespace=<insert-namespace-name-here>
kubectl get pods --namespace=<insert-namespace-name-here>

```

- Tuy nhiên không phải tất cả các resource sẽ được logic bởi namespace
```
[] kubectl api-resources --namespaced=false
NAME                              SHORTNAMES   APIGROUP                       NAMESPACED   KIND
componentstatuses                 cs                                          false        ComponentStatus
namespaces                        ns                                          false        Namespace
nodes                             no                                          false        Node
persistentvolumes                 pv                                          false        PersistentVolume
mutatingwebhookconfigurations                  admissionregistration.k8s.io   false        MutatingWebhookConfiguration
validatingwebhookconfigurations                admissionregistration.k8s.io   false        ValidatingWebhookConfiguration
customresourcedefinitions         crd,crds     apiextensions.k8s.io           false        CustomResourceDefinition
apiservices                                    apiregistration.k8s.io         false        APIService
tokenreviews                                   authentication.k8s.io          false        TokenReview
selfsubjectaccessreviews                       authorization.k8s.io           false        SelfSubjectAccessReview
selfsubjectrulesreviews                        authorization.k8s.io           false        SelfSubjectRulesReview
subjectaccessreviews                           authorization.k8s.io           false        SubjectAccessReview
certificatesigningrequests        csr          certificates.k8s.io            false        CertificateSigningRequest
bgpconfigurations                              crd.projectcalico.org          false        BGPConfiguration
bgppeers                                       crd.projectcalico.org          false        BGPPeer
blockaffinities                                crd.projectcalico.org          false        BlockAffinity
clusterinformations                            crd.projectcalico.org          false        ClusterInformation
felixconfigurations                            crd.projectcalico.org          false        FelixConfiguration
globalnetworkpolicies                          crd.projectcalico.org          false        GlobalNetworkPolicy
globalnetworksets                              crd.projectcalico.org          false        GlobalNetworkSet
hostendpoints                                  crd.projectcalico.org          false        HostEndpoint
ipamblocks                                     crd.projectcalico.org          false        IPAMBlock
ipamconfigs                                    crd.projectcalico.org          false        IPAMConfig
ipamhandles                                    crd.projectcalico.org          false        IPAMHandle
ippools                                        crd.projectcalico.org          false        IPPool
nodes                                          metrics.k8s.io                 false        NodeMetrics
ingressclasses                                 networking.k8s.io              false        IngressClass
runtimeclasses                                 node.k8s.io                    false        RuntimeClass
podsecuritypolicies               psp          policy                         false        PodSecurityPolicy
clusterrolebindings                            rbac.authorization.k8s.io      false        ClusterRoleBinding
clusterroles                                   rbac.authorization.k8s.io      false        ClusterRole
priorityclasses                   pc           scheduling.k8s.io              false        PriorityClass
csidrivers                                     storage.k8s.io                 false        CSIDriver
csinodes                                       storage.k8s.io                 false        CSINode
storageclasses                    sc           storage.k8s.io                 false        StorageClass
volumeattachments                              storage.k8s.io                 false        VolumeAttachment

```


### Label và selector

- Lable là một cặp key/value được gắn vào các object. Lable được sử dụng để người dùng nhận dạng các dạng tài nguyên, các objet có liên quan với nhau và không ảnh hướng đến các ứng dụng trong Pod 
- Bằng cách sử dụng lable người dùng có thể tìm kiếm một set object liên quan đến nhau. Dưới dây là một ví dụ lable selector
```

apiVersion: v1
kind: Pod
metadata:
  name: label-demo
  labels:
    environment: production
    app: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80
```
- Sau đó có thể tìm kiếm theo lable
```
kubectl get pods -l environment=production,tier=frontend

```
### Annotations
- Đối với Lable được sử dụng để định danh, tuy nhiên với Annotations được sủ định định danh sách môi trường cho Pod, ví dụ như git branch, các version, ID commit.




## Cài đặt Dashboard




- Khởi tạo cert ssl
```
openssl genrsa -des3 -passout pass:over4chars -out dashboard.pass.key 2048
openssl rsa -passin pass:over4chars -in dashboard.pass.key -out dashboard.key
  rm dashboard.pass.key
openssl req -new -key dashboard.key -out dashboard.csr

openssl x509 -req -sha256 -days 365 -in dashboard.csr -signkey dashboard.key -out dashboard.crt

```

- Taoj namespae
```
kubectl create namespace kubernetes-dashboard 
```

- Import secert
```
kubectl create secret generic kubernetes-dashboard-certs --from-file=$HOME/certs -n kubernetes-dashboard

```

- File object dashboard tại dashboard.yaml
```

apiVersion: v1
kind: Namespace
metadata:
  name: kubernetes-dashboard

---

apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard
---

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard

---

kind: Service
apiVersion: v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
spec:
  type: NodePort
  ports:
    - port: 443
      nodePort: 30036
      targetPort: 8443

  selector:
    k8s-app: kubernetes-dashboard

---

apiVersion: v1
kind: Secret
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard-certs
  namespace: kubernetes-dashboard
type: Opaque

---

apiVersion: v1
kind: Secret
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard-csrf
  namespace: kubernetes-dashboard
type: Opaque
data:
  csrf: ""

---

apiVersion: v1
kind: Secret
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard-key-holder
  namespace: kubernetes-dashboard
type: Opaque

---

kind: ConfigMap
apiVersion: v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard-settings
  namespace: kubernetes-dashboard

---

kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
rules:
  # Allow Dashboard to get, update and delete Dashboard exclusive secrets.
  - apiGroups: [""]
    resources: ["secrets"]
    resourceNames: ["kubernetes-dashboard-key-holder", "kubernetes-dashboard-certs", "kubernetes-dashboard-csrf"]
    verbs: ["get", "update", "delete"]
    # Allow Dashboard to get and update 'kubernetes-dashboard-settings' config map.
  - apiGroups: [""]
    resources: ["configmaps"]
    resourceNames: ["kubernetes-dashboard-settings"]
    verbs: ["get", "update"]
    # Allow Dashboard to get metrics.
  - apiGroups: [""]
    resources: ["services"]
    resourceNames: ["heapster", "dashboard-metrics-scraper"]
    verbs: ["proxy"]
  - apiGroups: [""]
    resources: ["services/proxy"]
    resourceNames: ["heapster", "http:heapster:", "https:heapster:", "dashboard-metrics-scraper", "http:dashboard-metrics-scraper"]
    verbs: ["get"]

---

kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
rules:
  # Allow Metrics Scraper to get metrics from the Metrics server
  - apiGroups: ["metrics.k8s.io"]
    resources: ["pods", "nodes"]
    verbs: ["get", "list", "watch"]

---

apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: kubernetes-dashboard
subjects:
  - kind: ServiceAccount
    name: kubernetes-dashboard
    namespace: kubernetes-dashboard

---

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kubernetes-dashboard
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kubernetes-dashboard
subjects:
  - kind: ServiceAccount
    name: kubernetes-dashboard
    namespace: kubernetes-dashboard

---

kind: Deployment
apiVersion: apps/v1
metadata:
  labels:
    k8s-app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kubernetes-dashboard
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      k8s-app: kubernetes-dashboard
  template:
    metadata:
      labels:
        k8s-app: kubernetes-dashboard
    spec:
      containers:
        - name: kubernetes-dashboard
          image: kubernetesui/dashboard:v2.0.0-rc7
          imagePullPolicy: Always
          ports:
            - containerPort: 8443
              protocol: TCP
          args:
            - --tls-cert-file=/dashboard.crt
            - --tls-key-file=/dashboard.key
            - --namespace=kubernetes-dashboard
            # Uncomment the following line to manually specify Kubernetes API server Host
            # If not specified, Dashboard will attempt to auto discover the API server and connect
            # to it. Uncomment only if the default does not work.
            # - --apiserver-host=http://my-address:port
          volumeMounts:
            - name: kubernetes-dashboard-certs
              mountPath: /certs
              # Create on-disk volume to store exec logs
            - mountPath: /tmp
              name: tmp-volume
          livenessProbe:
            httpGet:
              scheme: HTTPS
              path: /
              port: 8443
            initialDelaySeconds: 30
            timeoutSeconds: 30
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 1001
            runAsGroup: 2001
      volumes:
        - name: kubernetes-dashboard-certs
          secret:
            secretName: kubernetes-dashboard-certs
        - name: tmp-volume
          emptyDir: {}
      serviceAccountName: kubernetes-dashboard
      nodeSelector:
        "beta.kubernetes.io/os": linux
      # Comment the following tolerations if Dashboard must not be deployed on master
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule

---

kind: Service
apiVersion: v1
metadata:
  labels:
    k8s-app: dashboard-metrics-scraper
  name: dashboard-metrics-scraper
  namespace: kubernetes-dashboard
spec:
  ports:
    - port: 8000
      targetPort: 8000
  selector:
    k8s-app: dashboard-metrics-scraper

---

kind: Deployment
apiVersion: apps/v1
metadata:
  labels:
    k8s-app: dashboard-metrics-scraper
  name: dashboard-metrics-scraper
  namespace: kubernetes-dashboard
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      k8s-app: dashboard-metrics-scraper
  template:
    metadata:
      labels:
        k8s-app: dashboard-metrics-scraper
      annotations:
        seccomp.security.alpha.kubernetes.io/pod: 'runtime/default'
    spec:
      containers:
        - name: dashboard-metrics-scraper
          image: kubernetesui/metrics-scraper:v1.0.4
          ports:
            - containerPort: 8000
              protocol: TCP
          livenessProbe:
            httpGet:
              scheme: HTTP
              path: /
              port: 8000
            initialDelaySeconds: 30
            timeoutSeconds: 30
          volumeMounts:
          - mountPath: /tmp
            name: tmp-volume
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 1001
            runAsGroup: 2001
      serviceAccountName: kubernetes-dashboard
      nodeSelector:
        "beta.kubernetes.io/os": linux
      # Comment the following tolerations if Dashboard must not be deployed on master
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
      volumes:
        - name: tmp-volume
          emptyDir: {}
```

- Sau đó  thực hiện khởi tạo
```
kubectl create -f dashboard.yaml
```


- Get node Ip
```
kubectl get svc -A 
```

- Get  secret key
```
[root@master1 ~]# kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '{print $1}')
Name:         admin-user-token-qmvr2
Namespace:    kubernetes-dashboard
Labels:       <none>
Annotations:  kubernetes.io/service-account.name: admin-user
              kubernetes.io/service-account.uid: 3663f6df-460b-4bdb-bea9-609f66cfa408

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  20 bytes
token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IjBiTVE0WnRQdWo5QVlabExrS2FVamVxaEhZUmhJR2tLQkV6QTh1U3FqRTQifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLXFtdnIyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIzNjYzZjZkZi00NjBiLTRiZGItYmVhOS02MDlmNjZjZmE0MDgiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.B7-xHj8aXo12hgbqUFZN_I0zZ-TkeleoLrOXInd1kszCWXNwBaH-DiCswIzNMhk2VM7VWlmFG8JmCUcNkNe7xvSrF7BeDPwJXFkZJPVOxavkZQGzuJMAbYYOL6iO-Lz9qM8CcGpJnjnhhT8f_yTBR_-8SS4raGDLCxtvQa1sDOSByIT3ULrn-0BoGum3zubpdyQSqk59iYTfI47Vwxrn-daGZKRwp1wHO6uwoowS34VF7tokQAV9Km9wFi7g7uTbyEEXTWGDw56kBK7cCFo5T8GpNyw1SizfEQM3BWr3mVrfaPWIuzTZ9-Ng-ver4Uw94SPDvfPBbHRLRm3nGrSUOA

```

- Truy cập vào Dashboard thông qua địa chỉ của các node, cổng 30036. Ví dụ worker1:30036. Sau đso sử dụng token ở trên để đăng nhập

- Ngoài ra triển khai thêm metric server, thông qua trình lab sẽ sử dụng để theo dõi tài nguyên các Pod
```
wget https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.3.6/components.yaml

```

- Tại file compoment thực hiện cập nhật lại tại dòng arg
```
   args:
          - --cert-dir=/tmp
          - --secure-port=4443
          - --kubelet-insecure-tls
          - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
```

- Sau đó gõ  lệnh
```
kubectl create -f components.yaml
``` 


## Tìm hiểu về POD và Node trong Kubernetes

- Node trong K8S xét về phần cứng là đơn vị nhỏ nhất.
- Xem danh sách node
```
 kubectl get nodes

NAME                STATUS   ROLES    AGE   VERSION
worker1.novalocal   Ready    master   9d    v1.18.5
worker2.novalocal   Ready    <none>   9d    v1.18.5
worker3.novalocal   Ready    <none>   9d    v1.18.5
```


- Xem thông tin node
```
kubectl describe worker2.novalocal  
Name:               worker2.novalocal
Roles:              <none>
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=worker2.novalocal
                    kubernetes.io/os=linux
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock
                    node.alpha.kubernetes.io/ttl: 0
                    projectcalico.org/IPv4Address: 10.10.204.45/24
                    projectcalico.org/IPv4IPIPTunnelAddr: 192.168.196.128
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Tue, 30 Jun 2020 14:29:43 +0700
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  worker2.novalocal
  AcquireTime:     <unset>
  RenewTime:       Fri, 10 Jul 2020 11:26:05 +0700
Conditions:
  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----                 ------  -----------------                 ------------------                ------                       -------
  NetworkUnavailable   False   Thu, 02 Jul 2020 11:56:19 +0700   Thu, 02 Jul 2020 11:56:19 +0700   CalicoIsUp                   Calico is running on this node
  MemoryPressure       False   Fri, 10 Jul 2020 11:21:57 +0700   Tue, 30 Jun 2020 14:29:43 +0700   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure         False   Fri, 10 Jul 2020 11:21:57 +0700   Tue, 30 Jun 2020 14:29:43 +0700   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure          False   Fri, 10 Jul 2020 11:21:57 +0700   Tue, 30 Jun 2020 14:29:43 +0700   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready                True    Fri, 10 Jul 2020 11:21:57 +0700   Tue, 30 Jun 2020 14:39:46 +0700   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  10.10.204.45
  Hostname:    worker2.novalocal
Capacity:
  cpu:                8
  ephemeral-storage:  30831504Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             7909800Ki
  pods:               110
Allocatable:
  cpu:                8
  ephemeral-storage:  28414314040
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             7807400Ki
  pods:               110
System Info:
  Machine ID:                 295be744089dd6c628e454749a5a5198
  System UUID:                FDE1AB1D-65F4-4DFE-9844-7220050F110B
  Boot ID:                    0b33f072-6e42-4d85-9351-b9f6b32f2189
  Kernel Version:             3.10.0-1062.1.2.el7.x86_64
  OS Image:                   CentOS Linux 7 (Core)
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://19.3.8
  Kubelet Version:            v1.18.5
  Kube-Proxy Version:         v1.18.5
PodCIDR:                      10.20.1.0/24
PodCIDRs:                     10.20.1.0/24
Non-terminated Pods:          (10 in total)
  Namespace                   Name                                    CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE
  ---------                   ----                                    ------------  ----------  ---------------  -------------  ---
  cpu-example                 cpu-demo                                500m (6%)     1 (12%)     0 (0%)           0 (0%)         13h
  default                     kubernetes-bootcamp-6f6656d949-tvzqf    0 (0%)        0 (0%)      0 (0%)           0 (0%)         91m
  default                     nginx-56j2z                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         85m
  default                     nginx-deployment-7b45d69949-cg96r       0 (0%)        0 (0%)      0 (0%)           0 (0%)         79m
  default                     nginx-deployment-7b45d69949-vpdmq       0 (0%)        0 (0%)      0 (0%)           0 (0%)         75m
  default                     nginx-x4x5l                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         85m
  kube-system                 calico-node-2xqqp                       250m (3%)     0 (0%)      0 (0%)           0 (0%)         9d
  kube-system                 kube-proxy-wfkdq                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         9d
  kube-system                 metrics-server-c65c9d66-c274g           0 (0%)        0 (0%)      0 (0%)           0 (0%)         18h
  mem-example                 memory-demo                             0 (0%)        0 (0%)      100Mi (1%)       200Mi (2%)     18h
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                750m (9%)   1 (12%)
  memory             100Mi (1%)  200Mi (2%)
  ephemeral-storage  0 (0%)      0 (0%)
  hugepages-1Gi      0 (0%)      0 (0%)
  hugepages-2Mi      0 (0%)      0 (0%)
Events:              <none>

```

- Các thông số của node cần chú ý:

Addresses
  - HostName: Hostname của node
  - InternalIP: địa chỉ IP của node sử dụng trong nội bộ Cluster
  - ExternalIP: địa chỉ IP của node có hiểu lực từ ngoài cluster liên lạc đến
Conditions: thông tin trạng thái đang chạy của node, có các thông tin

  - Ready: giá trị true - chấp nhận triển khai chạy các Pod
  - MemoryPressure: giá trị true nếu cạn kiệt bộ nhớ
  - DiskPressure: giá trị true nếu cạn kiệt đĩa lưu trữ-NetworkUnavailable: giá trị true nếu cấu hình mạng lỗi
 


###  Pods trong Kubernetes
- Kubernetes không chạy các container một cách trực tiếp, thay vào đó nó bọc một hoặc vài container vào với nhau trong một cấu trúc gọi là POD. Các container cùng một pod thì chia sẻ với nhau tài nguyên và mạng cục bộ của pod.